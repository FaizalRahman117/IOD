{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T23:24:44.710131Z",
     "start_time": "2019-05-26T23:24:44.669241Z"
    },
    "colab_type": "text",
    "id": "Xk8fq5PNZBis"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXEmJGi6ZBiu"
   },
   "source": [
    "# Lab 6.6\n",
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIs6u55WZBiv"
   },
   "source": [
    "### Data\n",
    "\n",
    "**Predict the chronic kidney disease.**\n",
    "\n",
    "This dataset can be used to predict the chronic kidney disease and it can be collected from the hospital nearly 2 months of period.\n",
    "\n",
    "We use the following representation to collect the dataset \n",
    "- age\t-\tage\t\n",
    "- bp\t-\tblood pressure \n",
    "- sg\t-\tspecific gravity \n",
    "- al\t- albumin \n",
    "- su\t-\tsugar \n",
    "- rbc\t-\tred blood cells \n",
    "- pc\t-\tpus cell \n",
    "- pcc\t-\tpus cell clumps \n",
    "- ba\t-\tbacteria \n",
    "- bgr\t-\tblood glucose random \n",
    "- bu\t-\tblood urea \n",
    "- sc\t-\tserum creatinine \n",
    "- sod\t-\tsodium \n",
    "- pot\t-\tpotassium \n",
    "- hemo\t-\themoglobin \n",
    "- pcv\t-\tpacked cell volume \n",
    "- wc\t-\twhite blood cell count \n",
    "- rc\t-\tred blood cell count \n",
    "- htn\t-\thypertension \n",
    "- dm\t-\tdiabetes mellitus \n",
    "- cad\t-\tcoronary artery disease \n",
    "- appet\t-\tappetite \n",
    "- pe\t-\tpedal edema \n",
    "- ane\t-\tanemia \n",
    "- class\t-\tclass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Chronic Kidney Disease DataSet](https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:39:24.374436Z",
     "start_time": "2019-05-27T07:39:24.366509Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Uv3dx6ClZBiw"
   },
   "outputs": [],
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T23:51:34.682929Z",
     "start_time": "2019-05-26T23:51:34.678939Z"
    },
    "colab_type": "text",
    "id": "qCrSbU7lZBiz"
   },
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:39:40.506841Z",
     "start_time": "2019-05-27T07:39:40.502852Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1keyNaMwZBi0"
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "kidney_disease_csv = 'kidney_disease.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR_aDbYyZBi3"
   },
   "source": [
    "#### 2. Perform EDA\n",
    "\n",
    "Perform EDA. Check null values. Impute if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:16:54.288954Z",
     "start_time": "2019-05-27T01:16:54.283943Z"
    },
    "colab_type": "text",
    "id": "ysAGOB_cZBi4"
   },
   "source": [
    "#### Impute Null Values\n",
    "\n",
    "Impute null values for numeric and object columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2t_0S5u8ZBi6"
   },
   "source": [
    "#### 3. Label Encoder\n",
    "\n",
    "Encode labels with value between 0 and n_classes-1.\n",
    "\n",
    "> from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:41:30.821964Z",
     "start_time": "2019-05-27T07:41:30.817976Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "o2LDxMC1ZBi6"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T02:01:36.412363Z",
     "start_time": "2019-05-27T02:01:36.408368Z"
    },
    "colab_type": "text",
    "id": "0r59fpVAZBi9"
   },
   "source": [
    "#### 4. OneHotEncoder \n",
    "\n",
    "Encode categorical integer features as a one-hot numeric array.\n",
    "\n",
    "The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array.\n",
    "\n",
    "By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually. The OneHotEncoder previously assumed that the input features take on values in the range [0, max(values)). This behaviour is deprecated.\n",
    "\n",
    "This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.\n",
    "\n",
    "> from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:42:13.217369Z",
     "start_time": "2019-05-27T07:42:13.213356Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fcOMDwFAZBi-"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YM5nkSquZBjA"
   },
   "source": [
    "#### 5. Dummy Variables\n",
    "\n",
    "Convert categorical variable into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:42:33.522386Z",
     "start_time": "2019-05-27T07:42:33.518397Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Q-znAG71ZBjB"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IrBuSXDZBjE"
   },
   "source": [
    "####  6. Set Target \n",
    "\n",
    "Set `classification` as target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USH1cB-8ZBjE"
   },
   "source": [
    "#### 4. Select Feature\n",
    "\n",
    "The classes in the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets.\n",
    "\n",
    "##### 4.1 Univariate Selection\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the transform method:\n",
    "\n",
    "- SelectKBest removes all but the  highest scoring features\n",
    "- Use sklearn.feature_selection.chi2 as score function\n",
    "    > Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n",
    "\n",
    "\n",
    "More Reads:\n",
    "[Univariate feature selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "- Create an instance of SelectKBest\n",
    "    - Use sklearn.feature_selection.chi2 as score_func\n",
    "    - Use k of your choice\n",
    "- Fit X, y \n",
    "- Find top 4 features\n",
    "- Transform features to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:43:18.924798Z",
     "start_time": "2019-05-27T07:43:18.920809Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "a_Q5N0oXZBjF"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nfKmR0fZBjI"
   },
   "source": [
    "##### 4.2 Recursive feature elimination\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n",
    "More Reads:\n",
    "[Recursive feature elimination](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "- Use RFE to extract feature\n",
    "    - use LogisticRegression as estimator\n",
    "    - Number of n_features_to_select as of your choice\n",
    "- Fit X, y to RFE\n",
    "- Find Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:43:33.184464Z",
     "start_time": "2019-05-27T07:43:33.180498Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CooavWYMZBjI"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXKkl3LqZBjL"
   },
   "source": [
    "#### Create multiple Classifier Model\n",
    "\n",
    "Create multiple classifier models to predict the chronic kidney disease. Use any models of your choice. Evaluate all models and select the best model according to their performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kDuGiLojfFe"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA_Lab_6_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
