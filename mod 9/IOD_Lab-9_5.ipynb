{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXUiceLiLNOv"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmJwFqq5LNOx"
   },
   "source": [
    "# Demo 9.5: Working with Text\n",
    "- Using [NLTK](http://www.nltk.org) (Natural Language Toolkit)\n",
    "- Using [spaCy](https://spacy.io)\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I83eiiJqLNO0"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:02.954027Z",
     "start_time": "2020-10-07T06:27:01.413950Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-ecJn_1MLNO4"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import regex as re\n",
    "\n",
    "# conda install -c conda-forge spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsSgzr8MLNO9"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:02.961095Z",
     "start_time": "2020-10-07T06:27:02.957131Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HvyU9ZbtLNPA"
   },
   "outputs": [],
   "source": [
    "## Loading the data\n",
    "\n",
    "input_file = '../DATA/ncc-1701-D.txt'\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF9gBdpALNPE"
   },
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:02.968659Z",
     "start_time": "2020-10-07T06:27:02.964905Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-JImxUzrLNPG",
    "outputId": "13ce31ea-531e-4abd-8f21-c726df89bb21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5ePf_5bLNPK"
   },
   "source": [
    "## Work the data\n",
    "- if necessary or desired\n",
    "    - remove text or content, e.g. quotes (\") or metadata (===)\n",
    "    - add content or markers, e.g. (#FLAG, --NAME--)\n",
    "    - remove or convert special symbols, e.g. \"Ã©\" to \"e\"\n",
    "    - remove or convert emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:02.974518Z",
     "start_time": "2020-10-07T06:27:02.972444Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BRq7VfoOLNPM"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMG9Yim0LNPP"
   },
   "source": [
    "## Helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:02.983629Z",
     "start_time": "2020-10-07T06:27:02.977556Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3oIPRH3gLNPQ"
   },
   "outputs": [],
   "source": [
    "# create a bar chart of the frequency of the words in the text\n",
    "def plot_words(tokens, top = 30):\n",
    "    tokens_counter = Counter(tokens)\n",
    "    tok = [t for (t, _) in tokens_counter.most_common()]\n",
    "    val = [v for (_, v) in tokens_counter.most_common()]\n",
    "\n",
    "    plt.figure(figsize = (16, 6))\n",
    "    plt.bar(tok[:top], val[:top])\n",
    "    plt.title('Number of terms: %d' % len(tokens_counter))\n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1FsFC6yLNPS"
   },
   "source": [
    "## spaCy model invocation and text processing\n",
    "spaCy does the processing of the text as part of the reading of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.512678Z",
     "start_time": "2020-10-07T06:27:02.985594Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JgM48u-dLNPU"
   },
   "outputs": [],
   "source": [
    "# load spaCy and the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# process the text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8--KeYzLNPW"
   },
   "source": [
    "## Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.520458Z",
     "start_time": "2020-10-07T06:27:03.514874Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-7lVWo5DLNPe",
    "outputId": "b679dc9c-f19f-4ad2-fdbd-9b6755c17bae"
   },
   "outputs": [],
   "source": [
    "# only show the results\n",
    "# spaCy has done it already\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d| %r' % (i+1, t.text))\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.529986Z",
     "start_time": "2020-10-07T06:27:03.527209Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Gcg4Hkx4LNPh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ANSWER - Visualise the tokenised words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAtMzEZTLNPj"
   },
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.540660Z",
     "start_time": "2020-10-07T06:27:03.534759Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zOzudmrILNPq",
    "outputId": "1e58fcfc-674d-42f1-e82a-63f7d61a837a"
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "print('i | with stop words without')\n",
    "print('--| --------------- ------------')\n",
    "\n",
    "# for all the tokens\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d| %-15r %r' % (i+1, t.text, ('' if t.is_stop else t.text)))\n",
    "\n",
    "    # break after the first sentence\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.899378Z",
     "start_time": "2020-10-07T06:27:03.543763Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "B2LoqLmULNPs",
    "outputId": "63f83744-f889-462f-f166-d8add6a03f7e"
   },
   "outputs": [],
   "source": [
    "plot_words(['%r' % t.text for t in doc if not (t.is_stop | t.is_punct)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uqME12uLNPu"
   },
   "source": [
    "### Check Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.906982Z",
     "start_time": "2020-10-07T06:27:03.901455Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vD-BrcLALNPz",
    "outputId": "a26b4e4f-095a-4086-a8fe-841cbbfb5b05"
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d|%-12r : %-5s %s' % (i+1, t.text, t.pos_, t.tag_))\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:03.914723Z",
     "start_time": "2020-10-07T06:27:03.909364Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "448zp9_vLNQC",
    "outputId": "561168c1-3a42-449d-9be3-dd22182459c3"
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "print('i | Token        Lemma')\n",
    "print('--| ------------ ------------')\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d| %-12r %r' % (i+1, t.text, t.lemma_))\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.252720Z",
     "start_time": "2020-10-07T06:27:03.917101Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "i-7pqVMxLNQD",
    "outputId": "6deff35e-0d28-4351-bbab-7600618eb817"
   },
   "outputs": [],
   "source": [
    "plot_words(['%r' % t.lemma_ for t in doc if not (t.is_stop | t.is_punct)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHUdgHM7LNQF"
   },
   "source": [
    "### Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.308642Z",
     "start_time": "2020-10-07T06:27:04.255170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yyOrZ42oLNQH",
    "outputId": "dfcee498-0002-4064-98ca-fa11668978d5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "for i, s in enumerate(doc.sents):\n",
    "    print('%2d: %s' % (i, re.sub(r'\\n+', '', s.text)))\n",
    "    if s.as_doc().ents:\n",
    "        print('-'*80)\n",
    "        for e in s.as_doc().ents:\n",
    "            print('%-11s: %s' % (e.label_, re.sub(r'\\n+', '', e.text)))\n",
    "    print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Using NLTK for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:42:08.014090Z",
     "start_time": "2020-10-07T06:42:06.293808Z"
    }
   },
   "outputs": [],
   "source": [
    "# conda install -c anaconda nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Python interpreter, execute the following commands:\n",
    "\n",
    "- import nltk\n",
    "- nltk.download()\n",
    "\n",
    "At the NLTK Downloader GUI, install the following:\n",
    "\n",
    "- averaged_perceptron_tagger\n",
    "- ACE Named Entity Chunker (Maximum entropy)\n",
    "- Punkt Tokenizer Models\n",
    "- Stopwords Corpus\n",
    "- WordNet\n",
    "- Word Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.615658Z",
     "start_time": "2020-10-07T06:27:04.311241Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pML63M9KLNPX",
    "outputId": "29a6c627-0eee-4ece-bb34-47eacbbb53ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use nltk to find tokens\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "for i, t in enumerate(tokens[:25]):\n",
    "    print('%2d| %r' % (i+1, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.618540Z",
     "start_time": "2020-10-07T06:27:01.440Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "G5C3ituYLNPZ",
    "outputId": "db39aade-f506-4b45-ed1e-56327c19e4f7"
   },
   "outputs": [],
   "source": [
    "plot_words(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.620114Z",
     "start_time": "2020-10-07T06:27:01.441Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BnY2rFzuLNPj",
    "outputId": "f64087cd-8e4b-4df5-fb2d-7b04851bde34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stopWords.sort()\n",
    "print(', '.join(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.621900Z",
     "start_time": "2020-10-07T06:27:01.443Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dksPJF7YcI1o"
   },
   "outputs": [],
   "source": [
    "# ANSWER - create a list of tokens withOUT the stop words\n",
    "# NOTE: see the `.lower()` method applied to token\n",
    "tokens_no_stop = '' # create a list of tokens withOUT the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.623626Z",
     "start_time": "2020-10-07T06:27:01.444Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "a82KBILRLNPm",
    "outputId": "b33cef88-79ab-4e06-9c0e-9f2a4a588306"
   },
   "outputs": [],
   "source": [
    "## NLTK\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "print('i | with stop words without')\n",
    "print('--| --------------- ------------')\n",
    "\n",
    "# for all the tokens\n",
    "while i < len(tokens):\n",
    "    # same word\n",
    "    if tokens[i] == tokens_no_stop[j]:\n",
    "        print('%2d| %-15r %r' % (i+1, tokens[i], tokens_no_stop[j]))\n",
    "        j += 1\n",
    "    # not the same word\n",
    "    else:\n",
    "        print('%2d| %-15r' % (i+1, tokens[i]))\n",
    "\n",
    "    # next word\n",
    "    i += 1\n",
    "    # break after the first sentence\n",
    "    if tokens[i-1] == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.625071Z",
     "start_time": "2020-10-07T06:27:01.445Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uPtOoiwuLNPo"
   },
   "outputs": [],
   "source": [
    "# ANSWER - Create plot of words without stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.626712Z",
     "start_time": "2020-10-07T06:27:01.447Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KRupju0sLNPv"
   },
   "outputs": [],
   "source": [
    "# define PoS\n",
    "pos_list = {\n",
    "    'CC':   'coordinating conjunction',\n",
    "    'CD':   'cardinal digit',\n",
    "    'DT':   'determiner',\n",
    "    'EX':   'existential there (like: \"there is\" ... think of it like \"there exists\")',\n",
    "    'FW':   'foreign word',\n",
    "    'IN':   'preposition/subordinating conjunction',\n",
    "    'JJ':   'adjective \"big\"',\n",
    "    'JJR':  'adjective, comparative \"bigger\"',\n",
    "    'JJS':  'adjective, superlative \"biggest\"',\n",
    "    'LS':   'list marker 1)',\n",
    "    'MD':   'modal could, will',\n",
    "    'NN':   'noun, singular \"desk\"',\n",
    "    'NNS':  'noun plural \"desks\"',\n",
    "    'NNP':  'proper noun, singular \"Harrison\"',\n",
    "    'NNPS': 'proper noun, plural \"Americans\"',\n",
    "    'PDT':  'predeterminer \"all the kids\"',\n",
    "    'POS':  'possessive ending parent\"s',\n",
    "    'PRP':  'personal pronoun I, he, she',\n",
    "    'PRP$': 'possessive pronoun my, his, hers',\n",
    "    'RB':   'adverb very, silently,',\n",
    "    'RBR':  'adverb, comparative better',\n",
    "    'RBS':  'adverb, superlative best',\n",
    "    'RP':   'particle give up',\n",
    "    'TO':   'to go \"to\" the store.',\n",
    "    'UH':   'interjection errrrrrrrm',\n",
    "    'VB':   'verb, base form take',\n",
    "    'VBD':  'verb, past tense took',\n",
    "    'VBG':  'verb, gerund/present participle taking',\n",
    "    'VBN':  'verb, past participle taken',\n",
    "    'VBP':  'verb, sing. present, non-3d take',\n",
    "    'VBZ':  'verb, 3rd person sing. present takes',\n",
    "    'WDT':  'wh-determiner which',\n",
    "    'WP':   'wh-pronoun who, what',\n",
    "    'WP$':  'possessive wh-pronoun whose',\n",
    "    'WRB':  'wh-abverb where, when',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.628228Z",
     "start_time": "2020-10-07T06:27:01.448Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "asqUoCHgLNPx",
    "outputId": "6e3cab17-f736-49f3-ce62-8e759d72ac35",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "for i, t in enumerate(tagged[:25]):\n",
    "    print('%2d|%-12r : %-4s %s' % (i+1, t[0], t[1], (pos_list[t[1]] if t[1] in pos_list else '-')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_n9qMgyULNP1"
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.629787Z",
     "start_time": "2020-10-07T06:27:01.450Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pL1vRUzxLNP2"
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "stemmed = ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2d9a6QazLNP4"
   },
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.631193Z",
     "start_time": "2020-10-07T06:27:01.452Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OAbriUsXLNP7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "wl = nltk.stem.WordNetLemmatizer()\n",
    "lemma = ' '.join([wl.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.632590Z",
     "start_time": "2020-10-07T06:27:01.453Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yVIqX7HBLNP9",
    "outputId": "26f47e5f-7927-4ceb-e7aa-148b1a0d6798"
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "dot = stemmed.find('.') + 1\n",
    "sl = stemmed[:dot].split()\n",
    "dot = lemma.find('.') + 1\n",
    "ll = lemma[:dot].split()\n",
    "\n",
    "print('i | Stem           Lemma')\n",
    "print('--| -------------- ------------')\n",
    "for i, p in enumerate(zip(sl, ll)):\n",
    "    print('%2d| %-12r   %-12r' % (i+1, p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.634005Z",
     "start_time": "2020-10-07T06:27:01.455Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "eG4yOgwVLNP-",
    "outputId": "70476f16-7ac6-4c40-e39f-7a6547c11fec"
   },
   "outputs": [],
   "source": [
    "plot_words(stemmed.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.635904Z",
     "start_time": "2020-10-07T06:27:01.457Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uEJR57TYLNQA",
    "outputId": "e96f9bb4-cdfc-432c-b0af-bcdb3a6c2c6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_words(lemma.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:27:04.637228Z",
     "start_time": "2020-10-07T06:27:01.459Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sw6fYdgXLNQG",
    "outputId": "a83ea9db-825d-4031-8112-f022b71f565b"
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "\n",
    "for e in entities:\n",
    "    s = re.sub(r'[\\(\\)]', '', str(e))\n",
    "    if s.find('/NNP') > 0:\n",
    "        t = s.split()[0]\n",
    "        n = ' '.join([re.sub(r'/NNP', '', x) for x in s.split()[1:]])\n",
    "        print('%-12s: %s' % (t, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "Â© 2020 Institute of Data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab-9_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.976px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
